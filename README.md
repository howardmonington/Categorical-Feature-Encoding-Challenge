# Categorical Feature Encoding Challenge

#### -- Project Status: [Completed]

## Project Intro/Objective
The purpose of this project is to experiment with different types of categorical features, sampling methods, and predictive algorithms when implementing machine learning. 


### Methods Used
* Machine Learning
* Data Visualization (matplotlib)
* Label Encoding
* One Hot Encoding
* ROC AUC Score

### Technologies
* Python
* SGD, random_forest, extra_trees, KNeighbors, bernoulliNB, xgb
* pandas, numpy
* jupyter
* StratifiedShuffleSplit
* RandomOverSampler

## Project Description
This project presented the challenge of encoding various different types of features, including:
* binary features
* low- and high-cardinality nominal features
* low- and high-cardinality ordinal features

I worked differently with each of these types of features in order to perform feature engineering. Finally, I tested various different types of algorithms using 5 fold cross validation in order to find the best performing model.

### Dataset Location
The Raw Data can be found [here](https://www.kaggle.com/c/dont-overfit-ii)

## Featured Notebooks/Analysis/Deliverables
* [Notebook](https://github.com/lukemonington/Categorical-Feature-Encoding-Challenge/blob/master/categorical-feature-encoding-challenge.ipynb)


## Contributing Members

**[Luke Monington](https://github.com/lukemonington)**

## Contact
* I can be reached at lukemonington@aol.com.
